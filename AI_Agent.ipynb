{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmXvUp94xRtR",
        "outputId": "deea3da0-a485-48ed-fdce-6e00b3370d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training HMM for word length 1 with 46 words\n",
            "Training HMM for word length 2 with 84 words\n",
            "Training HMM for word length 3 with 388 words\n",
            "Training HMM for word length 4 with 1169 words\n",
            "Training HMM for word length 5 with 2340 words\n",
            "Training HMM for word length 6 with 3755 words\n",
            "Training HMM for word length 7 with 5111 words\n",
            "Training HMM for word length 8 with 6348 words\n",
            "Training HMM for word length 9 with 6808 words\n",
            "Training HMM for word length 10 with 6465 words\n",
            "Training HMM for word length 11 with 5452 words\n",
            "Training HMM for word length 12 with 4292 words\n",
            "Training HMM for word length 13 with 3094 words\n",
            "Training HMM for word length 14 with 2019 words\n",
            "Training HMM for word length 15 with 1226 words\n",
            "Training HMM for word length 16 with 698 words\n",
            "Training HMM for word length 17 with 375 words\n",
            "Training HMM for word length 18 with 174 words\n",
            "Training HMM for word length 19 with 88 words\n",
            "Training HMM for word length 20 with 40 words\n",
            "Training HMM for word length 21 with 16 words\n",
            "Training HMM for word length 22 with 8 words\n",
            "Training HMM for word length 23 with 3 words\n",
            "Training HMM for word length 24 with 1 words\n",
            "After guessing 'A':\n",
            "  E: 0.1647\n",
            "  R: 0.0963\n",
            "  O: 0.0942\n",
            "  I: 0.0740\n",
            "  N: 0.0730\n",
            "  T: 0.0655\n",
            "  S: 0.0577\n",
            "  C: 0.0479\n",
            "Updated pattern: _____\n",
            "\n",
            "After guessing 'E':\n",
            "  O: 0.1164\n",
            "  I: 0.1011\n",
            "  R: 0.0821\n",
            "  S: 0.0796\n",
            "  N: 0.0774\n",
            "  U: 0.0771\n",
            "  T: 0.0720\n",
            "  L: 0.0609\n",
            "Updated pattern: _____\n",
            "\n",
            "After guessing 'N':\n",
            "  O: 0.1198\n",
            "  R: 0.1007\n",
            "  I: 0.0881\n",
            "  S: 0.0875\n",
            "  U: 0.0785\n",
            "  T: 0.0775\n",
            "  L: 0.0775\n",
            "  H: 0.0715\n",
            "Updated pattern: ____N\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "\n",
        "# -------------------------\n",
        "# (unchanged) Load corpus\n",
        "# -------------------------\n",
        "def load_corpus(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        words = [line.strip().upper() for line in f if line.strip()]\n",
        "    return words\n",
        "\n",
        "# -------------------------\n",
        "# Train HMM (bigram Markov) on words for a given length\n",
        "# returns: start_prob (dict), transition_prob (dict of dicts)\n",
        "# -------------------------\n",
        "def train_hmm_for_words(words, alphabet=None, smoothing=1.0):\n",
        "    if alphabet is None:\n",
        "        all_letters = [chr(ord('A') + i) for i in range(26)]\n",
        "    else:\n",
        "        all_letters = alphabet\n",
        "\n",
        "    transitions = defaultdict(Counter)\n",
        "    start_letter_counter = Counter()\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) == 0:\n",
        "            continue\n",
        "        start_letter_counter[word[0]] += 1\n",
        "        for i in range(len(word) - 1):\n",
        "            current_letter = word[i]\n",
        "            next_letter = word[i + 1]\n",
        "            transitions[current_letter][next_letter] += 1\n",
        "\n",
        "    # start probs with add-k smoothing\n",
        "    total_starts = sum(start_letter_counter.values())\n",
        "    V = len(all_letters)\n",
        "    start_prob = {letter: (start_letter_counter[letter] + smoothing) / (total_starts + smoothing * V) for letter in all_letters}\n",
        "\n",
        "    transition_prob = {}\n",
        "    for letter in all_letters:\n",
        "        next_counts = transitions[letter]\n",
        "        total_next = sum(next_counts.values())\n",
        "        transition_prob[letter] = {\n",
        "            next_letter: (next_counts[next_letter] + smoothing) / (total_next + smoothing * V)\n",
        "            for next_letter in all_letters\n",
        "        }\n",
        "    return start_prob, transition_prob\n",
        "\n",
        "# -------------------------\n",
        "# Train HMMs for each word length (same as yours)\n",
        "# -------------------------\n",
        "def train_length_based_hmms(words, smoothing=1.0):\n",
        "    length_word_map = defaultdict(list)\n",
        "    for word in words:\n",
        "        length_word_map[len(word)].append(word)\n",
        "\n",
        "    length_hmm_models = {}\n",
        "    for length, words_of_length in sorted(length_word_map.items()):\n",
        "        print(f\"Training HMM for word length {length} with {len(words_of_length)} words\")\n",
        "        start_prob, transition_prob = train_hmm_for_words(words_of_length, smoothing=smoothing)\n",
        "        length_hmm_models[length] = (start_prob, transition_prob)\n",
        "    return length_hmm_models\n",
        "\n",
        "# -------------------------\n",
        "# Compute probability of a whole word under the bigram HMM\n",
        "# P(word) = start_prob[w0] * prod_{i=0..n-2} transition[w_i][w_{i+1}]\n",
        "# returns log-prob for numerical stability, and exp(logp) when needed\n",
        "# -------------------------\n",
        "def word_log_probability(word, start_prob, transition_prob):\n",
        "    if len(word) == 0:\n",
        "        return -math.inf\n",
        "    # use log-probs for stability\n",
        "    logp = math.log(start_prob.get(word[0], 1e-12))\n",
        "    for i in range(len(word) - 1):\n",
        "        a = word[i]\n",
        "        b = word[i + 1]\n",
        "        trans = transition_prob.get(a, None)\n",
        "        if trans is None:\n",
        "            # unseen prev-letter -> assume tiny prob\n",
        "            logp += math.log(1e-12)\n",
        "        else:\n",
        "            logp += math.log(trans.get(b, 1e-12))\n",
        "    return logp\n",
        "\n",
        "# -------------------------\n",
        "# Filter words matching pattern and avoiding guessed letters\n",
        "# pattern: list or string like ['_','A','_']\n",
        "# guessed_letters: set of letters guessed so far (both correct & incorrect)\n",
        "# This version enforces that letters already revealed in pattern match.\n",
        "# -------------------------\n",
        "def filter_words_by_pattern(words, pattern, guessed_letters):\n",
        "    filtered = []\n",
        "    pat_len = len(pattern)\n",
        "    for word in words:\n",
        "        if len(word) != pat_len:\n",
        "            continue\n",
        "        match = True\n",
        "        for wc, pc in zip(word, pattern):\n",
        "            if pc != '_' and pc != wc:\n",
        "                match = False\n",
        "                break\n",
        "            if pc == '_' and wc in guessed_letters:\n",
        "                # don't allow a word that has an already-guessed letter in an unrevealed spot\n",
        "                match = False\n",
        "                break\n",
        "        if match:\n",
        "            filtered.append(word)\n",
        "    return filtered\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Calculate letter probs using the HMM as an oracle:\n",
        "# Score each candidate (filtered) word by its HMM probability,\n",
        "# then sum (weight) unique occurrences of letters in remaining spots.\n",
        "# That returns P(letter | pattern, guessed_letters) approximated via word probabilities.\n",
        "# -------------------------\n",
        "def calculate_letter_probs_using_hmm(words_of_length, pattern, guessed_letters, hmm):\n",
        "    # hmm: (start_prob, transition_prob)\n",
        "    start_prob, transition_prob = hmm\n",
        "    # filter words consistent with current pattern & guessed letters\n",
        "    candidates = filter_words_by_pattern(words_of_length, pattern, guessed_letters)\n",
        "\n",
        "    # if no candidates, fallback to simple positional frequency\n",
        "    if not candidates:\n",
        "        # fallback: count letters at blank positions from all words_of_length\n",
        "        letter_counts = Counter()\n",
        "        total = 0\n",
        "        for w in words_of_length:\n",
        "            for idx, ch in enumerate(w):\n",
        "                if pattern[idx] == '_' and ch not in guessed_letters:\n",
        "                    letter_counts[ch] += 1\n",
        "                    total += 1\n",
        "        if total == 0:\n",
        "            return {chr(ord('A') + i): 0.0 for i in range(26)}\n",
        "        return {chr(ord('A') + i): (letter_counts[chr(ord('A') + i)] / total) for i in range(26)}\n",
        "\n",
        "    # compute log-probabilities for candidates\n",
        "    log_probs = [word_log_probability(w, start_prob, transition_prob) for w in candidates]\n",
        "    # normalize in log-space -> convert to probabilities\n",
        "    max_logp = max(log_probs)\n",
        "    probs = [math.exp(lp - max_logp) for lp in log_probs]  # subtract max for numerical stability\n",
        "    # normalize\n",
        "    s = sum(probs)\n",
        "    if s == 0:\n",
        "        # numeric fallback (rare)\n",
        "        probs = [1.0 / len(probs)] * len(probs)\n",
        "    else:\n",
        "        probs = [p / s for p in probs]\n",
        "\n",
        "    # weight letters: count each letter once per word (unique letters in that word that are in blank positions)\n",
        "    letter_scores = Counter()\n",
        "    for w, p in zip(candidates, probs):\n",
        "        # only count letters at blank positions (and not already guessed)\n",
        "        letters_here = set(ch for i, ch in enumerate(w) if pattern[i] == '_' and ch not in guessed_letters)\n",
        "        for L in letters_here:\n",
        "            letter_scores[L] += p\n",
        "\n",
        "    # normalize to probability distribution over alphabet\n",
        "    letters = [chr(ord('A') + i) for i in range(26)]\n",
        "    total_score = sum(letter_scores.values())\n",
        "    if total_score == 0:\n",
        "        return {L: 0.0 for L in letters}\n",
        "    return {L: (letter_scores[L] / total_score) for L in letters}\n",
        "\n",
        "# -------------------------\n",
        "# Example usage patch (replace your calculate loop with this snippet)\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    corpus_path = \"corpus.txt\"\n",
        "    all_words = load_corpus(corpus_path)\n",
        "\n",
        "    hmms = train_length_based_hmms(all_words, smoothing=1.0)\n",
        "\n",
        "    word_length = 5\n",
        "    words_of_length = [w for w in all_words if len(w) == word_length]\n",
        "\n",
        "    pattern = ['_'] * word_length\n",
        "    guessed_letters = set()\n",
        "\n",
        "    guesses = ['A', 'E', 'N']\n",
        "    for guess in guesses:\n",
        "        guessed_letters.add(guess)\n",
        "        # Use HMM to compute letter probabilities\n",
        "        hmm = hmms[word_length]\n",
        "        letter_probs = calculate_letter_probs_using_hmm(words_of_length, pattern, guessed_letters, hmm)\n",
        "\n",
        "        print(f\"After guessing '{guess}':\")\n",
        "        sorted_probs = sorted(letter_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "        for letter, prob in sorted_probs[:8]:\n",
        "            print(f\"  {letter}: {prob:.4f}\")\n",
        "\n",
        "        if guess == 'N':\n",
        "            pattern[-1] = 'N'\n",
        "        print(\"Updated pattern:\", \"\".join(pattern))\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# HANGMAN HYBRID RL (Q-LEARNING + HMM PRIORS)\n",
        "# Optimized for Hackathon Evaluation\n",
        "# ==========================\n",
        "\n",
        "import random, math\n",
        "from collections import defaultdict, Counter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# ENVIRONMENT\n",
        "# -------------------------\n",
        "class HangmanEnv:\n",
        "    def __init__(self, word, max_wrong=6):\n",
        "        self.word = word\n",
        "        self.word_set = set(word)\n",
        "        self.max_wrong = max_wrong\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.guessed = set()\n",
        "        self.wrong = 0\n",
        "        self.done = False\n",
        "        self.state = ['_' for _ in self.word]\n",
        "        return self._get_obs()\n",
        "\n",
        "    def _get_obs(self):\n",
        "        # returns (pattern, wrong_count, length)\n",
        "        return (''.join(self.state), self.wrong, len(self.word))\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Takes a letter as an action, returns next_state, reward, done, info.\"\"\"\n",
        "        if self.done:\n",
        "            return self._get_obs(), 0, True, {}\n",
        "\n",
        "        reward = 0\n",
        "        if action in self.guessed:\n",
        "            reward = -4  # repeated guess penalty\n",
        "        else:\n",
        "            self.guessed.add(action)\n",
        "            if action in self.word_set:\n",
        "                prev = self.state.copy()\n",
        "                for i, c in enumerate(self.word):\n",
        "                    if c == action:\n",
        "                        self.state[i] = action\n",
        "                new_reveals = sum(a != b for a, b in zip(self.state, prev))\n",
        "                reward = 10 * new_reveals  # reward for new reveals\n",
        "            else:\n",
        "                self.wrong += 1\n",
        "                reward = -7  # wrong guess penalty\n",
        "\n",
        "        if '_' not in self.state:\n",
        "            self.done = True\n",
        "            reward += 80  # win bonus\n",
        "        elif self.wrong >= self.max_wrong:\n",
        "            self.done = True\n",
        "            reward -= 40  # fail penalty\n",
        "\n",
        "        return self._get_obs(), reward, self.done, {}\n",
        "\n",
        "# -------------------------\n",
        "# UTILITIES\n",
        "# -------------------------\n",
        "def load_words(path):\n",
        "    with open(path, 'r') as f:\n",
        "        return [w.strip().upper() for w in f if w.strip()]\n",
        "\n",
        "def build_letter_priors(words):\n",
        "    \"\"\"Compute global unigram letter frequencies.\"\"\"\n",
        "    cnt = Counter()\n",
        "    total = 0\n",
        "    for w in words:\n",
        "        cnt.update(w)\n",
        "        total += len(w)\n",
        "    return {c: cnt[c] / total for c in cnt}\n",
        "\n",
        "def build_positional_priors(words):\n",
        "    \"\"\"Compute letter probabilities by position.\"\"\"\n",
        "    pos_counts = defaultdict(Counter)\n",
        "    pos_totals = Counter()\n",
        "    for w in words:\n",
        "        for i, ch in enumerate(w):\n",
        "            pos_counts[i][ch] += 1\n",
        "            pos_totals[i] += 1\n",
        "    pos_priors = {i: {ch: pos_counts[i][ch] / pos_totals[i] for ch in pos_counts[i]} for i in pos_counts}\n",
        "    return pos_priors\n",
        "\n",
        "# -------------------------\n",
        "# HYBRID Q-LEARNING AGENT\n",
        "# -------------------------\n",
        "class HybridQLearningAgent:\n",
        "    def __init__(self, hmm_priors, pos_priors, alpha=0.15, gamma=0.95, epsilon=0.3, epsilon_decay=0.9995, epsilon_min=0.05):\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
        "        self.actions = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
        "        self.hmm_priors = hmm_priors\n",
        "        self.pos_priors = pos_priors\n",
        "\n",
        "    def encode_state(self, obs):\n",
        "        pattern, wrong, length = obs\n",
        "        return pattern + f\"|{wrong}|{length}\"\n",
        "\n",
        "    def get_action(self, obs, guessed):\n",
        "        state = self.encode_state(obs)\n",
        "        available = [a for a in self.actions if a not in guessed]\n",
        "        if not available:\n",
        "            return random.choice(self.actions)\n",
        "\n",
        "        # epsilon-greedy with decay\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(available)\n",
        "\n",
        "        # bias with HMM + positional priors\n",
        "        pattern, _, _ = obs\n",
        "        hmm_bias = {}\n",
        "        for a in available:\n",
        "            base = self.hmm_priors.get(a, 0)\n",
        "            # add small boost if letter commonly appears in any blank position\n",
        "            pos_bonus = np.mean([self.pos_priors.get(i, {}).get(a, 0) for i, p in enumerate(pattern) if p == '_']) if '_' in pattern else 0\n",
        "            hmm_bias[a] = 0.3 * base + 0.7 * pos_bonus\n",
        "\n",
        "        q_values = {a: self.q_table[state][a] + 0.5 * hmm_bias.get(a, 0) for a in available}\n",
        "        return max(q_values, key=q_values.get)\n",
        "\n",
        "    def update(self, obs, action, reward, next_obs):\n",
        "        s = self.encode_state(obs)\n",
        "        s_next = self.encode_state(next_obs)\n",
        "        best_next = max(self.q_table[s_next].values(), default=0)\n",
        "        self.q_table[s][action] += self.alpha * (reward + self.gamma * best_next - self.q_table[s][action])\n",
        "        # decay epsilon\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "# -------------------------\n",
        "# TRAINING\n",
        "# -------------------------\n",
        "def train_agent(agent, train_words, episodes=20000):\n",
        "    # curriculum: short words ‚Üí long words\n",
        "    for ep in tqdm(range(episodes)):\n",
        "        if ep < 5000:\n",
        "            word = random.choice([w for w in train_words if len(w) <= 5])\n",
        "        elif ep < 15000:\n",
        "            word = random.choice([w for w in train_words if len(w) <= 7])\n",
        "        else:\n",
        "            word = random.choice(train_words)\n",
        "\n",
        "        env = HangmanEnv(word)\n",
        "        obs = env.reset()\n",
        "        while True:\n",
        "            action = agent.get_action(obs, env.guessed)\n",
        "            next_obs, reward, done, _ = env.step(action)\n",
        "            agent.update(obs, action, reward, next_obs)\n",
        "            obs = next_obs\n",
        "            if done:\n",
        "                break\n",
        "    return agent # Added return statement\n",
        "\n",
        "# -------------------------\n",
        "# EVALUATION\n",
        "# -------------------------\n",
        "def evaluate_agent(agent, test_words):\n",
        "    success = 0\n",
        "    total_wrong = 0\n",
        "    total_repeat = 0\n",
        "\n",
        "    for word in test_words:\n",
        "        env = HangmanEnv(word)\n",
        "        obs = env.reset()\n",
        "        while not env.done:\n",
        "            action = agent.get_action(obs, env.guessed)\n",
        "            if action in env.guessed:\n",
        "                total_repeat += 1\n",
        "            prev_wrong = env.wrong\n",
        "            _, _, done, _ = env.step(action)\n",
        "            if env.wrong > prev_wrong:\n",
        "                total_wrong += 1\n",
        "            obs = env._get_obs()\n",
        "        if '_' not in env.state:\n",
        "            success += 1\n",
        "\n",
        "    success_rate = success / len(test_words)\n",
        "    final_score = (success_rate * 2000) - (total_wrong * 5) - (total_repeat * 2)\n",
        "    return success_rate, total_wrong, total_repeat, final_score\n",
        "\n",
        "# -------------------------\n",
        "# MAIN EXECUTION\n",
        "# -------------------------\n",
        "train_words = load_words(\"corpus.txt\")\n",
        "test_words = load_words(\"test.txt\")\n",
        "\n",
        "hmm_priors = build_letter_priors(train_words)\n",
        "pos_priors = build_positional_priors(train_words)\n",
        "\n",
        "agent = HybridQLearningAgent(\n",
        "    hmm_priors=hmm_priors,\n",
        "    pos_priors=pos_priors,\n",
        "    alpha=0.15,\n",
        "    gamma=0.95,\n",
        "    epsilon=0.3,\n",
        "    epsilon_decay=0.9995,\n",
        "    epsilon_min=0.05\n",
        ")\n",
        "\n",
        "print(\"Training hybrid agent...\")\n",
        "train_agent(agent, train_words, episodes=20000)\n",
        "\n",
        "print(\"\\nEvaluating...\")\n",
        "sr, tw, tr, fs = evaluate_agent(agent, test_words)\n",
        "\n",
        "print(\"\\n===== FINAL RESULTS =====\")\n",
        "print(f\"‚úÖ Success Rate: {sr*100:.2f}%\")\n",
        "print(f\"‚ùå Total Wrong Guesses: {tw}\")\n",
        "print(f\"üîÅ Total Repeated Guesses: {tr}\")\n",
        "print(f\"üèÜ Final Score: {fs:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLSIUWHS6RWi",
        "outputId": "0a4b70ad-082e-4924-8b71-89232545f7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training hybrid agent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20000/20000 [01:22<00:00, 243.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n",
            "\n",
            "===== FINAL RESULTS =====\n",
            "‚úÖ Success Rate: 14.85%\n",
            "‚ùå Total Wrong Guesses: 11401\n",
            "üîÅ Total Repeated Guesses: 0\n",
            "üèÜ Final Score: -56708.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio numpy\n"
      ],
      "metadata": {
        "id": "V5X_Vwvt_5dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# ----------------------------\n",
        "# 1Ô∏è‚É£ HMM Training Functions\n",
        "# ----------------------------\n",
        "def load_corpus(filepath='/content/corpus.txt'):\n",
        "    # Example fallback if no file given\n",
        "    if filepath is None:\n",
        "        words = [\"apple\", \"book\", \"data\", \"cat\", \"dog\", \"banana\", \"paper\", \"people\"]\n",
        "    else:\n",
        "        with open(filepath, 'r') as f:\n",
        "            words = [line.strip().lower() for line in f if line.strip()]\n",
        "    return words\n",
        "\n",
        "def build_letter_priors(words):\n",
        "    counts = Counter(\"\".join(words))\n",
        "    total = sum(counts.values())\n",
        "    return {ch: c / total for ch, c in counts.items()}\n",
        "\n",
        "def build_positional_priors(words):\n",
        "    pos_priors = defaultdict(Counter)\n",
        "    for w in words:\n",
        "        for i, ch in enumerate(w):\n",
        "            pos_priors[i][ch] += 1\n",
        "    # Normalize\n",
        "    for i in pos_priors:\n",
        "        total = sum(pos_priors[i].values())\n",
        "        for ch in pos_priors[i]:\n",
        "            pos_priors[i][ch] /= total\n",
        "    return pos_priors\n",
        "\n",
        "# ----------------------------\n",
        "# 2Ô∏è‚É£ Hybrid Q-Learning Agent\n",
        "# ----------------------------\n",
        "class HybridQLearningAgent:\n",
        "    def __init__(self, hmm_priors, pos_priors, alpha=0.15, gamma=0.95, epsilon=0.3,\n",
        "                 epsilon_decay=0.9995, epsilon_min=0.05):\n",
        "        self.hmm_priors = hmm_priors\n",
        "        self.pos_priors = pos_priors\n",
        "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "\n",
        "    def get_action(self, obs, guessed):\n",
        "        pattern, _, _ = obs\n",
        "        available = [ch for ch in \"abcdefghijklmnopqrstuvwxyz\" if ch not in guessed]\n",
        "        state = pattern\n",
        "\n",
        "        # If no unknowns, return done\n",
        "        if \"_\" not in pattern:\n",
        "            return None\n",
        "\n",
        "        # HMM + positional priors\n",
        "        hmm_bias = {}\n",
        "        for a in available:\n",
        "            base = self.hmm_priors.get(a, 0)\n",
        "            pos_bonus = np.mean([\n",
        "                self.pos_priors.get(i, {}).get(a, 0)\n",
        "                for i, p in enumerate(pattern)\n",
        "                if p == '_'\n",
        "            ]) if '_' in pattern else 0\n",
        "            hmm_bias[a] = 0.3 * base + 0.7 * pos_bonus\n",
        "\n",
        "        # Combine with Q-values\n",
        "        q_values = {a: self.q_table[state][a] + 0.5 * hmm_bias.get(a, 0) for a in available}\n",
        "\n",
        "        # Choose best letter\n",
        "        best = max(q_values, key=q_values.get)\n",
        "        return best\n",
        "\n",
        "# ----------------------------\n",
        "# 3Ô∏è‚É£ Initialize Data & Agent\n",
        "# ----------------------------\n",
        "words = load_corpus('/content/test.txt')\n",
        "hmm_priors = build_letter_priors(words)\n",
        "pos_priors = build_positional_priors(words)\n",
        "agent = HybridQLearningAgent(hmm_priors, pos_priors)\n",
        "\n",
        "# ----------------------------\n",
        "# 4Ô∏è‚É£ Prediction Logic\n",
        "# ----------------------------\n",
        "def predict_word(masked_word):\n",
        "    masked_word = masked_word.lower().strip()\n",
        "    if not masked_word or '_' not in masked_word:\n",
        "        return \"Please enter a masked word like '_p__e'.\"\n",
        "\n",
        "    guessed = set([ch for ch in masked_word if ch != '_'])\n",
        "    obs = (masked_word, 0, 6)\n",
        "    next_guess = agent.get_action(obs, guessed)\n",
        "\n",
        "    if next_guess is None:\n",
        "        return \"Word seems complete!\"\n",
        "    return f\"ü§ñ Suggested next letter: '{next_guess.upper()}'\"\n",
        "\n",
        "# ----------------------------\n",
        "# 5Ô∏è‚É£ Gradio UI\n",
        "# ----------------------------\n",
        "with gr.Blocks(title=\"Hangman Word Predictor (HMM + RL)\") as demo:\n",
        "    gr.Markdown(\"## üß© Hangman Predictor (Hybrid HMM + Q-Learning)\")\n",
        "    gr.Markdown(\"Enter a masked word (use `_` for unknown letters). Example: `_p__e`\")\n",
        "\n",
        "    masked_input = gr.Textbox(label=\"Masked Word\", placeholder=\"_p__e\", max_lines=1)\n",
        "    predicted_output = gr.Textbox(label=\"Model Suggestion\")\n",
        "\n",
        "    predict_btn = gr.Button(\"Predict Next Letter\")\n",
        "    predict_btn.click(fn=predict_word, inputs=masked_input, outputs=predicted_output)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "gyzfown5AEVU",
        "outputId": "04879db2-267b-48dd-ed18-2ac6c259418b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a073a8d333d31fb442.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a073a8d333d31fb442.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}